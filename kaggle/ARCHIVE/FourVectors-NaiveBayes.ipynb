{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('DATA/train.csv', header=0,  encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features / vectors: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Since relevance is an aggregate, values are continuous rather than discrete\n",
    "# It appears the classifier can only handle a limited number of values\n",
    "# So we round up\n",
    "train['relevance_rounded'] = train['relevance'].map(lambda x: round(x))\n",
    "\n",
    "# Create the feature 'exact match', allowing only for differences in case\n",
    "train['exact'] = pd.Series([True if st.lower() in pt.lower() else False \n",
    "                      for st, pt in zip(train['search_term'], train['product_title'])])\n",
    "\n",
    "# Create the feature 'overlapping words', allowing for differences in case\n",
    "train['overlapping_words'] = pd.Series([len(set(st.lower().split()) & set(pt.lower().split()))\n",
    "                      for st, pt in zip(train['search_term'], train['product_title'])])\n",
    "\n",
    "# Feature: percentage 'overlapping words', allowing for differences in case\n",
    "train['percentage_overlapping_words'] = pd.Series([len(set(st.lower().split()) & set(pt.lower().split()))/float(len(st.split()))\n",
    "                      for st, pt in zip(train['search_term'], train['product_title'])])\n",
    "\n",
    "# Feature: jaccard distance\n",
    "def jaccard_dist(phrase1, phrase2):\n",
    "    '''Returns the Jaccard distance for two phrases, eg, search query and product title'''\n",
    "    lst1, lst2 = set(phrase1.lower().split()), set(phrase2.lower().split())\n",
    "    return float(len(lst1 & lst2)) / len(lst1 | lst2)\n",
    "\n",
    "train['jaccard'] = pd.Series([jaccard_dist(st, pt) \n",
    "                      for st, pt in zip(train['search_term'], train['product_title'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare to divide the dataset into test, train (lifted from sklearn Iris example)\n",
    "train['is_train'] = np.random.uniform(0, 1, len(train)) <= .75\n",
    "\n",
    "# Split data into training and test\n",
    "train_data, test_data = train[train['is_train']==True], train[train['is_train']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds      1     2     3\n",
      "actual                  \n",
      "1        328   182   782\n",
      "2       2483  2415  3912\n",
      "3       1855  4194  2588\n"
     ]
    }
   ],
   "source": [
    "features = train.columns[[7, 8, 9, 10]] # Whether it's an exact match or not\n",
    "\n",
    "# clf = RandomForestClassifier(n_jobs=2)\n",
    "clf = RandomForestClassifier(n_jobs=2, class_weight = 'balanced', oob_score = False, criterion = 'entropy')\n",
    "\n",
    "y, _ = pd.factorize(train_data['relevance_rounded']) # 0, 1, 2\n",
    "\n",
    "clf.fit(train_data[features], y)\n",
    "\n",
    "# Predicting on those features will output predictions that match y\n",
    "preds = clf.predict(test_data[features])\n",
    "\n",
    "# target_names = test['relevance_rounded']\n",
    "target_names = ['1', '2', '3', '4']\n",
    "out = [target_names[pred] for pred in preds]\n",
    "\n",
    "# preds.index = range(len(preds))\n",
    "# pd.crosstab(test['relevance_rounded'], preds, rownames=['actual'], colnames=['preds'])\n",
    "ct = pd.crosstab(test_data['relevance_rounded'], np.asarray(out), rownames=['actual'], colnames=['preds'])\n",
    "print (ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crosstab summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5331 13408 13408 50886\n"
     ]
    }
   ],
   "source": [
    "index = list(pd.crosstab(test_data['relevance_rounded'], preds))\n",
    "total = 0\n",
    "for i in list(ct):\n",
    "    total += sum(list(ct[i]))\n",
    "\n",
    "true_positives  = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "true_negatives  = 0\n",
    "\n",
    "for i in zip(list(ct), range(1, len(ct)+1)):\n",
    "    row = list(ct.ix[i[1]])\n",
    "    column = list(ct[i[0]])\n",
    "    tp = row[i[1]-1]\n",
    "    true_positives  += tp\n",
    "    false_negatives += sum(row)-tp\n",
    "    false_positives += sum(column) - tp\n",
    "    true_negatives += total - tp\n",
    "    \n",
    "print(true_positives, false_positives, false_negatives, true_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28448689898073537"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://en.m.wikipedia.org/wiki/F1_score\n",
    "\n",
    "f1 = float(2*true_positives) / (2 * true_positives + false_positives + false_negatives)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds      1     2\n",
      "actual            \n",
      "1       1011   281\n",
      "2       5616  3194\n",
      "3       4197  4440\n"
     ]
    }
   ],
   "source": [
    "clf_nb = GaussianNB()\n",
    "clf_nb.fit(train_data[features], y)\n",
    "\n",
    "preds = clf_nb.predict(test_data[features])\n",
    "\n",
    "target_names = ['1', '2', '3', '4']\n",
    "out = [target_names[pred] for pred in preds]\n",
    "\n",
    "# Predicting on those features will output predictions that match y\n",
    "\n",
    "print(pd.crosstab(test_data['relevance_rounded'], np.asarray(out), rownames=['actual'], colnames=['preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0                 0     1\n",
      "relevance_rounded            \n",
      "1                  1011   281\n",
      "2                  5616  3194\n",
      "3                  4197  4440\n"
     ]
    }
   ],
   "source": [
    "ct = pd.crosstab(test_data['relevance_rounded'], preds)\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
